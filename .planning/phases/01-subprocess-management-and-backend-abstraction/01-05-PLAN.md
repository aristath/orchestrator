---
phase: 01-subprocess-management-and-backend-abstraction
plan: 05
type: execute
wave: 3
depends_on: ["01-02", "01-03", "01-04"]
files_modified:
  - internal/backend/process_test.go
  - internal/backend/backend_test.go
  - testdata/mock-cli.sh
autonomous: true

must_haves:
  truths:
    - "10+ sequential subprocess invocations leave zero zombie processes"
    - "ProcessManager.KillAll terminates all tracked subprocess trees"
    - "Concurrent pipe reading does not deadlock on large output"
    - "All three backend types can be created via the factory function"
    - "Context cancellation terminates running subprocess"
  artifacts:
    - path: "internal/backend/process_test.go"
      provides: "Subprocess infrastructure tests: pipe reading, process groups, zombie prevention"
      contains: "TestNoZombie"
    - path: "internal/backend/backend_test.go"
      provides: "Factory and integration tests across all backend types"
      contains: "TestFactory"
    - path: "testdata/mock-cli.sh"
      provides: "Mock CLI script that simulates agent CLI behavior for testing"
      contains: "#!/bin/bash"
  key_links:
    - from: "internal/backend/process_test.go"
      to: "internal/backend/process.go"
      via: "Tests executeCommand, ProcessManager, signal handling"
      pattern: "executeCommand|ProcessManager|KillAll"
    - from: "internal/backend/backend_test.go"
      to: "internal/backend/backend.go"
      via: "Tests factory function with all backend types"
      pattern: "New.*Config"
---

<objective>
Validate the subprocess infrastructure with stress tests for zombie prevention, deadlock prevention, signal propagation, and factory correctness.

Purpose: The subprocess patterns (concurrent pipe reading, process groups, ProcessManager) are the most critical and error-prone parts of Phase 1. These tests prove they work under stress and edge cases, satisfying the phase's core success criteria.
Output: Comprehensive test suite proving zero zombies, no deadlocks, proper signal propagation, and correct factory behavior.
</objective>

<execution_context>
@/Users/aristath/.claude/get-shit-done/workflows/execute-plan.md
@/Users/aristath/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-subprocess-management-and-backend-abstraction/01-RESEARCH.md
@.planning/phases/01-subprocess-management-and-backend-abstraction/01-01-SUMMARY.md
@.planning/phases/01-subprocess-management-and-backend-abstraction/01-02-SUMMARY.md
@.planning/phases/01-subprocess-management-and-backend-abstraction/01-03-SUMMARY.md
@.planning/phases/01-subprocess-management-and-backend-abstraction/01-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create mock CLI script and subprocess stress tests</name>
  <files>testdata/mock-cli.sh, internal/backend/process_test.go</files>
  <action>
1. Create `testdata/mock-cli.sh` — a bash script that simulates agent CLI behavior:
   ```bash
   #!/bin/bash
   # Mock CLI for testing subprocess management
   # Usage: mock-cli.sh [options]
   #   --echo "text"     : Echo text as JSON to stdout
   #   --large-output N  : Generate N KB of output (for deadlock testing)
   #   --sleep N         : Sleep for N seconds (for signal testing)
   #   --spawn-child     : Spawn a child process (for process tree testing)
   #   --exit-code N     : Exit with code N
   ```
   Implement each option:
   - `--echo`: Output `{"content": "$TEXT"}` to stdout
   - `--large-output`: Generate specified KB of JSON output (repeated `{"line": N}` objects, one per line)
   - `--sleep`: Sleep for N seconds, handle SIGTERM gracefully
   - `--spawn-child`: Fork a background `sleep 300` child before doing work (simulates agent CLI spawning subprocesses)
   - `--exit-code`: Exit with specified code
   Make the script executable: `chmod +x testdata/mock-cli.sh`

2. Create `internal/backend/process_test.go` with:

   **Test: `TestExecuteCommand_BasicExecution`**
   - Run `echo "hello"` via executeCommand
   - Verify stdout contains "hello", stderr is empty, no error

   **Test: `TestExecuteCommand_ConcurrentPipeReading_LargeOutput`**
   - Run mock-cli.sh with `--large-output 256` (256KB, well above 64KB pipe buffer)
   - Verify executeCommand returns without deadlock (use test timeout)
   - Verify stdout contains expected number of lines
   - This is the critical BACK-05 test — proves concurrent pipe reading prevents deadlock

   **Test: `TestExecuteCommand_StderrCapture`**
   - Run a command that writes to stderr (e.g., `bash -c "echo error >&2; echo ok"`)
   - Verify both stdout and stderr are captured correctly

   **Test: `TestExecuteCommand_ContextCancellation`**
   - Create context with short timeout (500ms)
   - Run mock-cli.sh with `--sleep 30` (longer than timeout)
   - Verify executeCommand returns error (context deadline exceeded or killed)
   - Verify subprocess is terminated

   **Test: `TestProcessManager_TrackAndKillAll`**
   - Create ProcessManager
   - Start mock-cli.sh with `--sleep 300` (long-running) via newCommand (not executeCommand — we want it running)
   - Manually start it with cmd.Start()
   - Track it with ProcessManager
   - Verify Count() = 1
   - Call KillAll()
   - Verify subprocess is terminated (cmd.Wait returns error)
   - Verify Count() = 0 after Untrack

   **Test: `TestProcessManager_KillsProcessTree`**
   - Start mock-cli.sh with `--spawn-child --sleep 30`
   - Track with ProcessManager
   - Call KillAll()
   - Wait briefly, then check that no child processes remain:
     Use `pgrep -P <pid>` or check that the process group is gone
   - This validates BACK-06 (process group signal propagation)

   **Test: `TestNoZombieProcesses_StressTest`**
   - Run 15 sequential subprocess invocations using executeCommand:
     Each runs mock-cli.sh with `--echo "test-N"`
   - After all complete, wait 1 second
   - Check for zombie processes: run `ps -o pid,stat` and look for "Z" state processes
   - Verify zero zombies found
   - This validates BACK-07 and the phase success criterion of 10+ sequential invocations

   **Test: `TestExecuteCommand_NonZeroExitCode`**
   - Run mock-cli.sh with `--exit-code 1`
   - Verify executeCommand returns an error
   - Verify stdout and stderr are still captured despite error
  </action>
  <verify>
`go test ./internal/backend/ -v -run "TestExecuteCommand|TestProcessManager|TestNoZombie" -timeout 60s` — all tests pass.
  </verify>
  <done>
All subprocess infrastructure tests pass: concurrent pipe reading handles 256KB+ output without deadlock, ProcessManager kills tracked processes and their children, 15 sequential invocations produce zero zombies, context cancellation terminates subprocesses.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add factory and cross-backend tests</name>
  <files>internal/backend/backend_test.go</files>
  <action>
Create `internal/backend/backend_test.go` with:

1. `TestFactory_CreatesClaudeAdapter`: Call `New(Config{Type: "claude"}, pm)`. Verify no error. Verify returned Backend has non-empty SessionID().

2. `TestFactory_CreatesCodexAdapter`: Call `New(Config{Type: "codex"}, pm)`. Verify no error.

3. `TestFactory_CreatesGooseAdapter`: Call `New(Config{Type: "goose"}, pm)`. Verify no error. Verify returned Backend has non-empty SessionID().

4. `TestFactory_UnknownType`: Call `New(Config{Type: "unknown"}, pm)`. Verify error is returned containing "unknown backend type".

5. `TestFactory_AllTypesImplementBackend`: For each type ("claude", "codex", "goose"):
   - Create via factory
   - Verify the returned value satisfies the Backend interface (compile-time, but also call SessionID() and Close() to verify runtime behavior)

6. `TestFactory_PassesConfig`: Create each adapter with specific Config fields (Model: "test-model", WorkDir: "/tmp/test"). Verify SessionID() works (proxy for adapter being properly initialized).

7. `TestAllAdapters_CloseIsIdempotent`: For each backend type, call Close() twice. Verify no error or panic on second call.

Run the full test suite to make sure nothing is broken:
`go test ./... -v -timeout 120s`
  </action>
  <verify>
`go test ./internal/backend/ -v -timeout 120s` — ALL tests pass (process tests, adapter tests, factory tests). Zero failures.
  </verify>
  <done>
Factory correctly creates all three adapter types. Unknown types return clear error. All adapters are closeable and implement Backend interface. Full test suite passes with zero failures, validating the complete Phase 1 implementation.
  </done>
</task>

</tasks>

<verification>
- `go test ./... -v -timeout 120s` — entire test suite passes
- Zero zombie processes after stress test (15+ sequential invocations)
- No deadlock on 256KB+ subprocess output
- ProcessManager kills process trees via process groups
- Context cancellation terminates subprocesses
- Factory creates all three adapter types correctly
</verification>

<success_criteria>
All Phase 1 success criteria are validated by tests:
1. Backend interface exists with Send/Close (verified by compile + factory tests)
2. Claude Code adapter builds correct commands (verified by unit tests in 01-02)
3. Codex adapter builds correct commands (verified by unit tests in 01-03)
4. Goose adapter supports local LLMs via --provider/--model (verified by unit tests in 01-04)
5. No pipe deadlocks on large output (verified by 256KB stress test)
6. Process group signal propagation kills subprocess trees (verified by KillsProcessTree test)
7. Zero zombies after 15 sequential invocations (verified by stress test)
</success_criteria>

<output>
After completion, create `.planning/phases/01-subprocess-management-and-backend-abstraction/01-05-SUMMARY.md`
</output>
