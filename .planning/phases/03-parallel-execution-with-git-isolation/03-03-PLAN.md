---
phase: 03-parallel-execution-with-git-isolation
plan: 03
type: execute
wave: 2
depends_on: ["03-01", "03-02"]
files_modified:
  - internal/orchestrator/runner.go
  - internal/orchestrator/runner_test.go
autonomous: true

must_haves:
  truths:
    - "2-4 agents execute concurrently with bounded concurrency -- no more than the configured limit run simultaneously"
    - "Each running agent operates in its own git worktree, isolated from other agents' file changes"
    - "When an agent completes, its worktree branch is merged back to the main branch via the configured merge strategy"
    - "A satellite agent can ask the orchestrator a clarifying question and receive an answer without blocking other running agents"
    - "All worktrees are cleaned up on both success and graceful shutdown"
    - "Merge conflicts on one task do not prevent other tasks from completing"
  artifacts:
    - path: "internal/orchestrator/runner.go"
      provides: "ParallelRunner with Run method wiring errgroup, worktree manager, executor, and QA channel"
      exports: ["ParallelRunner", "NewParallelRunner", "ParallelRunnerConfig", "TaskResult"]
    - path: "internal/orchestrator/runner_test.go"
      provides: "Integration tests for parallel execution with worktrees"
  key_links:
    - from: "internal/orchestrator/runner.go"
      to: "internal/worktree/manager.go"
      via: "WorktreeManager.Create/Merge/Cleanup per task"
      pattern: "wtManager\\.(Create|Merge|Cleanup)"
    - from: "internal/orchestrator/runner.go"
      to: "golang.org/x/sync/errgroup"
      via: "errgroup.WithContext + SetLimit"
      pattern: "errgroup\\.WithContext.*SetLimit"
    - from: "internal/orchestrator/runner.go"
      to: "internal/orchestrator/qa_channel.go"
      via: "QAChannel passed to task execution context"
      pattern: "qaChannel"
    - from: "internal/orchestrator/runner.go"
      to: "internal/backend"
      via: "Backend.Send with WorkDir set to worktree path"
      pattern: "backend\\.Send"
---

<objective>
Parallel runner that executes DAG-eligible tasks concurrently using errgroup.SetLimit, git worktrees for isolation, and the QA channel for orchestrator communication. Includes integration tests.

Purpose: This plan wires together all Phase 3 components (worktree manager from Plan 01, QA channel from Plan 02) with existing Phase 2 infrastructure (DAG, executor, backends) to deliver the complete parallel execution system. Satisfies all four EXEC requirements.
Output: internal/orchestrator/runner.go with ParallelRunner and integration tests.
</objective>

<execution_context>
@/Users/aristath/.claude/get-shit-done/workflows/execute-plan.md
@/Users/aristath/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-parallel-execution-with-git-isolation/03-RESEARCH.md
@.planning/phases/03-parallel-execution-with-git-isolation/03-01-SUMMARY.md
@.planning/phases/03-parallel-execution-with-git-isolation/03-02-SUMMARY.md
@internal/scheduler/task.go
@internal/scheduler/dag.go
@internal/scheduler/executor.go
@internal/backend/types.go
@internal/backend/backend.go
@internal/worktree/types.go
@internal/worktree/manager.go
@internal/orchestrator/qa_channel.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: ParallelRunner implementation</name>
  <files>internal/orchestrator/runner.go</files>
  <action>
Add `golang.org/x/sync` dependency: `go get golang.org/x/sync@latest`

Create `internal/orchestrator/runner.go`:

Types:
- `TaskResult` struct: `TaskID string`, `Success bool`, `MergeResult *worktree.MergeResult`, `Error error`.
- `ParallelRunnerConfig` struct: `ConcurrencyLimit int` (default 4), `MergeStrategy worktree.MergeStrategy`, `WorktreeManager *worktree.WorktreeManager`, `QAChannel *QAChannel` (optional, nil disables Q&A).

`ParallelRunner` struct:
- `config ParallelRunnerConfig`
- `dag *scheduler.DAG`
- `backends map[string]backend.Backend` (agentRole -> backend)
- `lockMgr *scheduler.ResourceLockManager`
- `mu sync.Mutex` (guards activeWorktrees and results)
- `activeWorktrees map[string]*worktree.WorktreeInfo`
- `results []TaskResult`

`NewParallelRunner(cfg ParallelRunnerConfig, dag *scheduler.DAG, lockMgr *scheduler.ResourceLockManager) *ParallelRunner`:
- Initialize with empty backends map, empty activeWorktrees map.
- Default concurrency limit to 4 if not set.

`RegisterBackend(agentRole string, b backend.Backend)`:
- Same pattern as scheduler.Executor.

`Run(ctx context.Context) ([]TaskResult, error)`:
- On entry, call `config.WorktreeManager.Prune()` to clean stale worktrees from prior crashes (log warning if fails, don't abort).
- If QAChannel is configured, call `config.QAChannel.Start(ctx)`, defer `config.QAChannel.Stop()`.
- `defer` cleanup: iterate `activeWorktrees`, call `ForceCleanup` on each. This catches shutdown/panic paths.
- Main execution loop (runs until no more eligible tasks and no running tasks):
  - Get eligible tasks from `dag.Eligible()`.
  - If no eligible and no running tasks, break (all done or all blocked).
  - Create `errgroup.WithContext(ctx)`, call `g.SetLimit(config.ConcurrencyLimit)` BEFORE any `g.Go()`.
  - For each eligible task, call `g.Go(func() error { return runner.executeTask(ctx, task) })`.
  - Call `g.Wait()`. If error and context is cancelled, return results + context error.
  - After wave completes, check for more eligible tasks (next wave). Loop continues.
- Return accumulated results.

`executeTask(ctx context.Context, task *scheduler.Task) error` (unexported):
- Check `ctx.Err()` early.
- Mark task running in DAG: `dag.MarkRunning(task.ID)`.
- Create worktree: `config.WorktreeManager.Create(task.ID)`. On error, mark task failed, return nil (error in DAG per Phase 2 pattern).
- Track worktree: `mu.Lock()`, add to `activeWorktrees`, `mu.Unlock()`.
- Look up backend for `task.AgentRole`. If not found, cleanup worktree, mark failed, return nil.
- Acquire file locks: `lockMgr.LockAll(task.WritesFiles)`, defer `lockMgr.UnlockAll(task.WritesFiles)`.
- Create a backend.Config clone with `WorkDir` set to worktree path. Since backends are pre-created and WorkDir is set at creation time, the runner needs to create per-task backend instances OR modify existing backends to accept WorkDir per-Send. Simpler approach: use `backend.New()` with a config that has `WorkDir: worktreePath` for each task. This creates a fresh backend per task execution. Store the ProcessManager reference in ParallelRunnerConfig for backend creation.
  - Add `ProcessManager *backend.ProcessManager` to `ParallelRunnerConfig`.
  - Add `BackendConfigs map[string]backend.Config` to `ParallelRunnerConfig` -- maps agentRole to base backend.Config. Runner clones the config and sets WorkDir per task.
  - In executeTask: clone config, set WorkDir to worktree path, call `backend.New(clonedCfg, config.ProcessManager)` to get a per-task backend.
- Send prompt: `b.Send(ctx, backend.Message{Content: task.Prompt, Role: "user"})`.
- On Send error: mark task failed, cleanup worktree (ForceCleanup), remove from activeWorktrees, record result, return nil.
- On Send success: mark task completed with response.
- Merge worktree: `config.WorktreeManager.Merge(wtInfo, config.MergeStrategy)`.
  - If merge fails (conflict): record TaskResult with MergeResult showing conflict, log warning, call Cleanup (branch is kept for user inspection). Do NOT mark task as failed -- the work succeeded, only merge failed.
  - If merge succeeds: call Cleanup, remove from activeWorktrees.
- Record TaskResult, return nil.

Important design notes:
- `g.Go()` functions return nil (not the error) because task failure tracking is in the DAG, not in errgroup. The errgroup is only for concurrency bounding and context cancellation. Only return non-nil for unrecoverable errors (context cancellation).
- The loop pattern: get eligible -> launch wave -> wait -> repeat. This naturally handles DAG waves -- Wave 1 tasks run, complete, then Wave 2 tasks become eligible.
- File locks prevent concurrent writes to same file even within a wave.
  </action>
  <verify>
`go build ./internal/orchestrator/...` compiles without errors.
`go vet ./internal/orchestrator/...` reports no issues.
  </verify>
  <done>ParallelRunner creates worktrees per task, executes with bounded concurrency via errgroup.SetLimit, merges results back, cleans up on all paths, supports QA channel.</done>
</task>

<task type="auto">
  <name>Task 2: Integration tests for parallel runner</name>
  <files>internal/orchestrator/runner_test.go</files>
  <action>
Create `internal/orchestrator/runner_test.go`.

Helper: `setupTestRepo(t *testing.T) string` -- same as Plan 01 tests: temp dir, git init, checkout -b main, initial commit. Return path.

Helper: `mockBackendConfig(role string) backend.Config` -- returns Config with Type "claude" (or whichever is simplest to mock).

For testing, create a simple mock backend that implements `backend.Backend`:
- `type mockBackend struct { responses map[string]string; workDir string; sendCount int; mu sync.Mutex }`
- `Send()` returns a canned response based on message content, increments sendCount.
- `Close()` is no-op. `SessionID()` returns "mock".
- Since the runner creates backends per task via `backend.New()`, tests need a different approach. Use `RegisterBackend` with pre-created mocks, and adjust the runner to accept either registered backends OR BackendConfigs for per-task creation. Simpler for testing: register backends directly. The runner checks registered backends first, falls back to creating from BackendConfigs.

Alternatively, keep it simpler: add a `BackendFactory func(role string, workDir string) (backend.Backend, error)` field to ParallelRunnerConfig. The runner calls this to get a backend per task. Tests provide a mock factory. Production code provides a factory that uses backend.New with the right config. This avoids coupling runner tests to backend internals.

Tests:
1. `TestParallelExecution_TwoIndependentTasks` -- Create DAG with two tasks (no dependencies). Set concurrency limit to 4. Run. Verify: both tasks complete, both worktree branches are merged (check git log for merge commits), results contain 2 successes. Use a mock backend factory that writes a unique file in the worktree to prove isolation (e.g., task "A" writes "fileA.txt", task "B" writes "fileB.txt"). After merges, both files exist in main.

2. `TestBoundedConcurrency` -- Create DAG with 4 independent tasks. Set concurrency limit to 2. Use a mock backend factory with artificial delay (100ms). Track concurrent execution count with atomic counter (increment on start, decrement on finish). Verify: max concurrent never exceeds 2.

3. `TestDAGWaves` -- Create DAG: task A (no deps), task B depends on A. Run. Verify: A completes before B starts (check execution order via timestamps or ordered log). Both succeed.

4. `TestMergeConflict_DoesNotBlockOthers` -- Create DAG with 3 independent tasks. Mock backend for task "conflict" writes to the SAME file that exists in main (creating a conflict). Other two tasks write unique files. Run. Verify: the two clean tasks merge successfully, the conflict task's result shows merge failure, overall run completes (not aborted).

5. `TestQAChannel_IntegratedWithRunner` -- Create DAG with one task. Mock backend factory that, during Send(), calls `qaChannel.Ask()` to ask a question. Provide an AnswerFunc that returns a canned answer. Run. Verify: task completes, answer was used (check response content or side effect).

6. `TestCleanupOnContextCancel` -- Create DAG with 2 slow tasks (200ms delay). Start run, cancel context after 50ms. Verify: Run returns promptly, all worktrees are cleaned up (no leftover directories in .worktrees/), `git worktree list` shows only main.

7. `TestPruneOnStartup` -- Manually create a stale worktree entry (create dir, then remove it to leave metadata). Run the parallel runner. Verify: no errors related to stale worktrees (prune handled it).

All tests use `-race` flag. Each test creates its own temp repo via `setupTestRepo`. Use `t.Cleanup` for any additional cleanup needed.
  </action>
  <verify>
`go test -race -v ./internal/orchestrator/...` -- all tests pass.
`go test -race ./internal/...` -- all tests pass (no regressions).
  </verify>
  <done>7 integration tests covering: parallel independent tasks, bounded concurrency enforcement, DAG wave ordering, merge conflict isolation, QA channel integration, cleanup on cancellation, and stale worktree pruning. All pass under -race.</done>
</task>

</tasks>

<verification>
- `go build ./internal/...` compiles
- `go vet ./internal/...` is clean
- `go test -race -v ./internal/orchestrator/...` all pass
- `go test -race ./internal/...` all pass (full suite, no regressions)
- Phase 3 success criteria from ROADMAP verified:
  1. 2-4 agents execute concurrently with bounded concurrency (TestBoundedConcurrency)
  2. Each agent in own git worktree (TestParallelExecution_TwoIndependentTasks)
  3. Completed work merged back (TestParallelExecution_TwoIndependentTasks, TestMergeConflict)
  4. Satellite agent Q&A works (TestQAChannel_IntegratedWithRunner)
</verification>

<success_criteria>
- ParallelRunner executes eligible tasks concurrently up to configured limit
- Each task runs in its own git worktree with isolated file system
- Completed task branches are merged back to main via configured strategy
- Merge conflicts on one task do not block other tasks
- QA channel allows asking orchestrator questions during execution
- All worktrees cleaned up on normal completion and context cancellation
- All 7 integration tests pass under -race
- No regressions in existing Phase 1/2 test suites
</success_criteria>

<output>
After completion, create `.planning/phases/03-parallel-execution-with-git-isolation/03-03-SUMMARY.md`
</output>
