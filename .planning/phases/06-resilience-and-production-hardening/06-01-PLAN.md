---
phase: 06-resilience-and-production-hardening
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - internal/orchestrator/resilience.go
  - internal/orchestrator/resilience_test.go
  - internal/orchestrator/runner.go
  - internal/orchestrator/runner_test.go
autonomous: true

must_haves:
  truths:
    - "A transient backend failure is retried with exponential backoff and jitter, eventually succeeding without user intervention"
    - "A persistently failing backend trips a circuit breaker that fails fast instead of wasting time on doomed retries"
    - "One agent failing does not cause unrelated parallel agents to abort — they continue independently"
    - "Context cancellation (Ctrl+C) stops retries immediately via backoff.Permanent"
  artifacts:
    - path: "internal/orchestrator/resilience.go"
      provides: "sendWithRetry function, circuit breaker factory, error classification"
      contains: "sendWithRetry"
    - path: "internal/orchestrator/resilience_test.go"
      provides: "Tests for retry, circuit breaker, and failure isolation"
      min_lines: 80
    - path: "internal/orchestrator/runner.go"
      provides: "Updated executeTask using sendWithRetry, plain errgroup for failure isolation"
      contains: "new(errgroup.Group)"
  key_links:
    - from: "internal/orchestrator/runner.go"
      to: "internal/orchestrator/resilience.go"
      via: "executeTask calls sendWithRetry"
      pattern: "sendWithRetry"
    - from: "internal/orchestrator/resilience.go"
      to: "backend.Send"
      via: "retry wraps backend.Send inside circuit breaker"
      pattern: "cb\\.Execute"
---

<objective>
Add retry with exponential backoff, per-backend circuit breakers, and failure isolation to the parallel runner.

Purpose: RESIL-01, RESIL-02, RESIL-03 — transient failures are retried automatically, persistently failing backends are circuit-broken to fail fast, and one agent's failure does not cascade to unrelated agents.

Output: `resilience.go` with retry+circuit breaker logic, updated `runner.go` with failure isolation, comprehensive tests.
</objective>

<execution_context>
@/Users/aristath/.claude/get-shit-done/workflows/execute-plan.md
@/Users/aristath/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-resilience-and-production-hardening/06-RESEARCH.md
@internal/orchestrator/runner.go
@internal/orchestrator/runner_test.go
@internal/backend/backend.go
@internal/backend/types.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create resilience.go with retry, circuit breaker, and error classification</name>
  <files>internal/orchestrator/resilience.go</files>
  <action>
First, install dependencies:
```
cd /Users/aristath/orchestrator && go get github.com/cenkalti/backoff/v4 && go get github.com/sony/gobreaker
```

Create `internal/orchestrator/resilience.go` with:

1. **RetryConfig struct** with fields:
   - InitialInterval (default 100ms)
   - MaxInterval (default 10s)
   - MaxElapsedTime (default 2min)
   - Multiplier (default 2.0)
   - RandomizationFactor (default 0.5)

2. **DefaultRetryConfig() function** returning the defaults above.

3. **CircuitBreakerRegistry struct** — holds a map of `*gobreaker.CircuitBreaker` keyed by backend type string (e.g., "claude", "codex", "goose"), with a sync.Mutex for thread-safe creation. This implements per-backend-type circuit breakers as recommended in research.
   - `NewCircuitBreakerRegistry() *CircuitBreakerRegistry`
   - `Get(backendType string) *gobreaker.CircuitBreaker` — returns existing or creates new with settings:
     - Name: backendType
     - MaxRequests: 3 (half-open test requests)
     - Interval: 0 (don't clear counts automatically)
     - Timeout: 30s (stay open for 30s before testing recovery)
     - ReadyToTrip: consecutive failures >= 5
     - OnStateChange: log.Printf the state transition
     - IsSuccessful: return true if err==nil or errors.Is(err, context.Canceled) or errors.Is(err, context.DeadlineExceeded) — don't count user cancellation as backend failure

4. **sendWithRetry function** with signature:
   ```go
   func sendWithRetry(ctx context.Context, b backend.Backend, msg backend.Message, cb *gobreaker.CircuitBreaker, retryCfg RetryConfig) (backend.Response, error)
   ```
   Implementation:
   - Declare `var resp backend.Response`
   - Create `operation := func() error { ... }` that:
     - Checks `ctx.Err()` first — if context cancelled, return `backoff.Permanent(ctx.Err())`
     - Calls `cb.Execute(func() (interface{}, error) { return b.Send(ctx, msg) })`
     - If error is `gobreaker.ErrOpenState` or `gobreaker.ErrTooManyRequests`, return `backoff.Permanent(err)` — don't retry against an open circuit
     - If error is non-nil and context is cancelled, return `backoff.Permanent(err)`
     - Otherwise return err (will be retried)
     - On success, cast result to `backend.Response` and store in resp
   - Create `backoff.NewExponentialBackOff(...)` from retryCfg fields
   - Wrap with `backoff.WithContext(backoffPolicy, ctx)`
   - Call `backoff.Retry(operation, backoffWithContext)`
   - Return resp, err

Do NOT add any unused helper functions. Keep the file focused on these 4 items.
  </action>
  <verify>
Run `cd /Users/aristath/orchestrator && go build ./internal/orchestrator/...` — should compile without errors.
  </verify>
  <done>resilience.go compiles, exports sendWithRetry, RetryConfig, DefaultRetryConfig, CircuitBreakerRegistry with Get method</done>
</task>

<task type="auto">
  <name>Task 2: Wire resilience into runner.go, switch to plain errgroup, add tests</name>
  <files>internal/orchestrator/runner.go, internal/orchestrator/runner_test.go, internal/orchestrator/resilience_test.go</files>
  <action>
**Modify runner.go:**

1. Add `RetryConfig` and `CircuitBreakerRegistry` fields to `ParallelRunnerConfig`:
   ```go
   RetryConfig          RetryConfig              // Retry configuration (zero value uses defaults)
   CircuitBreakerRegistry *CircuitBreakerRegistry // Optional (nil creates default on first use)
   ```

2. Add `cbRegistry *CircuitBreakerRegistry` field to `ParallelRunner` struct.

3. In `NewParallelRunner`, initialize cbRegistry:
   ```go
   cbRegistry := cfg.CircuitBreakerRegistry
   if cbRegistry == nil {
       cbRegistry = NewCircuitBreakerRegistry()
   }
   ```
   And apply RetryConfig defaults if zero-valued:
   ```go
   if cfg.RetryConfig == (RetryConfig{}) {
       cfg.RetryConfig = DefaultRetryConfig()
   }
   ```

4. **Switch from errgroup.WithContext to plain errgroup.Group** in `Run()` method.
   Change:
   ```go
   g, gctx := errgroup.WithContext(ctx)
   ```
   To:
   ```go
   g := new(errgroup.Group)
   ```
   And change the g.Go closure to pass `ctx` instead of `gctx`:
   ```go
   g.Go(func() error {
       return r.executeTask(ctx, t)
   })
   ```
   After `g.Wait()`, remove the `if ctx.Err() != nil` check that was there for the errgroup-derived context. Instead just log if err != nil:
   ```go
   if err := g.Wait(); err != nil {
       log.Printf("Wave completed with errors: %v", err)
   }
   ```

5. **In executeTask**, replace the direct `b.Send(ctx, msg)` call with:
   ```go
   backendType := r.backendType(task)
   cb := r.cbRegistry.Get(backendType)
   resp, err := sendWithRetry(ctx, b, backend.Message{Content: task.Prompt, Role: "user"}, cb, r.config.RetryConfig)
   ```
   Remove the old `resp, err := b.Send(ctx, backend.Message{...})` line. The error handling after remains the same.

6. In `executeTask`, change `return nil` at the end of error handling for Send failures — this is already correct (errors tracked in DAG, nil returned to errgroup).

**Create resilience_test.go** with:

1. **TestSendWithRetry_TransientThenSuccess**: Create a mock backend that fails twice then succeeds. Verify sendWithRetry returns success, and the mock's Send was called 3 times.

2. **TestSendWithRetry_PermanentFailure_CircuitOpen**: Create a mock backend that always fails. Call sendWithRetry 6+ times (to trip the circuit at 5 consecutive failures). Verify that after the 5th failure, subsequent calls return gobreaker.ErrOpenState quickly (circuit is open).

3. **TestSendWithRetry_ContextCancelled_StopsRetry**: Create a mock backend that always fails. Cancel context after 200ms. Verify sendWithRetry returns quickly with context error (not stuck retrying for 2 minutes).

4. **TestCircuitBreakerRegistry_PerBackendType**: Create registry, call Get("claude") twice — verify same instance. Call Get("codex") — verify different instance.

**Add to runner_test.go:**

5. **TestFailureIsolation_IndependentTasks**: Create DAG with 3 independent tasks. Mock backend: task-1 fails (returns error), task-2 and task-3 succeed. Run and verify:
   - task-1 is marked Failed in DAG
   - task-2 and task-3 are marked Completed
   - Results contain all 3 tasks
   - task-2 and task-3 have Success=true
   This proves RESIL-03: one failure doesn't cancel others.

For test mock backends in resilience_test.go, create a simple `retryTestBackend` struct implementing backend.Backend with a configurable `responses` slice (each entry is either a Response or error, consumed in order). SessionID() returns "test" and Close() is no-op.

Use short retry config in tests: InitialInterval=10ms, MaxInterval=50ms, MaxElapsedTime=1s to keep tests fast.
  </action>
  <verify>
Run `cd /Users/aristath/orchestrator && go test -race -v ./internal/orchestrator/... -count=1` — all tests must pass including existing tests and new resilience tests.
  </verify>
  <done>
- runner.go uses plain errgroup.Group (no WithContext) for failure isolation
- runner.go executeTask calls sendWithRetry with circuit breaker
- Transient failures are retried with exponential backoff (test proves 3 attempts)
- Circuit breaker opens after 5 consecutive failures (test proves fast-fail)
- Context cancellation stops retries immediately (test proves quick exit)
- One task failure does not cancel other parallel tasks (test proves isolation)
- All existing tests continue to pass
  </done>
</task>

</tasks>

<verification>
1. `go test -race -v ./internal/orchestrator/... -count=1` — all tests pass
2. `go build ./...` — full project compiles
3. `go vet ./internal/orchestrator/...` — no warnings
4. Verify `runner.go` contains `new(errgroup.Group)` (not `errgroup.WithContext`)
5. Verify `resilience.go` imports cenkalti/backoff/v4 and sony/gobreaker
</verification>

<success_criteria>
- Transient failures retried with exponential backoff and jitter (RESIL-01)
- Circuit breaker trips after 5 consecutive failures per backend type (RESIL-02)
- Plain errgroup provides failure isolation — one task fails, others continue (RESIL-03)
- All 20+ existing tests still pass with -race flag
- New resilience tests pass: retry success, circuit open, context cancel, isolation
</success_criteria>

<output>
After completion, create `.planning/phases/06-resilience-and-production-hardening/06-01-SUMMARY.md`
</output>
